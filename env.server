# Server Environment Configuration
# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=2
DEBUG=false

# Server-hosted Model Configuration (Replace with actual server model endpoint)
# Option 1: If server has a local model service
SERVER_MODEL_ENDPOINT=http://183.82.7.228:9519
SERVER_MODEL_API_KEY=your_server_model_api_key_here

# Option 2: If using a different hosted model service
# SERVER_MODEL_ENDPOINT=https://your-server-model-service.com/generate
# SERVER_MODEL_API_KEY=your_server_model_api_key_here

# Fallback: Keep Mistral for now (will be replaced)
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_MODEL=mistral-small-latest

# Embedding Configuration (Open-source sentence transformers)
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_MODEL_DIMENSION=384
EMBEDDING_BATCH_SIZE=32

# Server-hosted Qdrant Database Settings (Replace with actual server Qdrant details)
QDRANT_HOST=0.0.0.0
QDRANT_PORT=6333
QDRANT_API_KEY=dhsuhdujhisduygh
VECTOR_DB_NAME=rag_embeddings
VECTOR_DB_DIMENSION=384
VECTOR_DB_METRIC=cosine

# Server Storage Settings
REFERENCE_DOCUMENTS_DIR=./reference_documents
STORAGE_DIR=./storage
EMBEDDINGS_DIR=./storage/embeddings
UPLOAD_DIR=./storage/uploads

# LlamaIndex Settings
LLAMA_INDEX_CACHE_DIR=./storage/cache
LLAMA_INDEX_PERSIST_DIR=./storage/persist

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=./logs/rag_system.log

# LlamaIndex Chunking Settings
CHUNK_SIZE=1024
CHUNK_OVERLAP=200
CHUNK_SEPARATOR=\n\n

# Retrieval Configuration
RETRIEVAL_TOP_K=5
RETRIEVAL_SCORE_THRESHOLD=0.3
CONTEXT_MAX_TOKENS=4000
CONTEXT_OVERLAP=200
